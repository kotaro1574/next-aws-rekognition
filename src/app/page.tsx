"use client";

import Image from "next/image";
import { useRef, useState } from "react";
import Webcam from "react-webcam";

interface FaceDetail {
  age: {
    low?: number;
    high?: number;
  };
  gender?: string;
  genderConfidence?: number;
  emotion?: string;
  emotionConfidence?: number;
  smile?: boolean;
  eyeglasses?: boolean;
  sunglasses?: boolean;
  beard?: boolean;
  mustache?: boolean;
  eyesOpen?: boolean;
  mouthOpen?: boolean;
}

interface FaceAnalysisResult {
  success: boolean;
  message: string;
  faceCount?: number;
  faceDetails?: FaceDetail[];
}

// æ„Ÿæƒ…ã®è‹±èªåã‹ã‚‰æ—¥æœ¬èªã¸ã®å¤‰æ›é–¢æ•°
const translateEmotion = (emotion?: string): string => {
  if (!emotion) return "ä¸æ˜ â“";

  const emotionMap: Record<string, string> = {
    HAPPY: "å–œã³ ğŸ˜„",
    SAD: "æ‚²ã—ã¿ ğŸ˜¢",
    ANGRY: "æ€’ã‚Š ğŸ˜ ",
    CONFUSED: "å›°æƒ‘ ğŸ˜•",
    DISGUSTED: "å«Œæ‚ª ğŸ¤¢",
    SURPRISED: "é©šã ğŸ˜²",
    CALM: "å¹³é™ ğŸ˜Œ",
    FEAR: "ææ€– ğŸ˜±",
    UNKNOWN: "ä¸æ˜ â“",
  };

  return emotionMap[emotion] || `${emotion} â“`;
};

export default function Home() {
  const webcamRef = useRef<Webcam>(null);
  const [facingMode, setFacingMode] = useState<"user" | "environment">("user");
  const [image, setImage] = useState<string | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState<boolean>(false);
  const [faceAnalysisResult, setFaceAnalysisResult] =
    useState<FaceAnalysisResult | null>(null);

  const switchCamera = () => {
    setFacingMode((prevMode) => (prevMode === "user" ? "environment" : "user"));
  };

  const capture = () => {
    const imageSrc = webcamRef.current?.getScreenshot();
    if (imageSrc) {
      setImage(imageSrc);
    }
  };

  const analyzeImage = async () => {
    if (!image) return;

    try {
      setIsAnalyzing(true);

      const response = await fetch("/api/analyze-face", {
        method: "POST",
        body: JSON.stringify({ imageData: image }),
        headers: { "Content-Type": "application/json" },
      });

      const result = await response.json();
      setFaceAnalysisResult(result);
    } catch (error) {
      console.error("åˆ†æã‚¨ãƒ©ãƒ¼:", error);
      setFaceAnalysisResult({
        success: false,
        message: "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
      });
    } finally {
      setIsAnalyzing(false);
    }
  };

  return (
    <div className="max-w-100 mx-auto p-4 flex flex-col items-center gap-4">
      <h1 className="text-2xl font-bold">é¡”èªè¨¼</h1>

      <Webcam
        className="rounded-lg"
        ref={webcamRef}
        videoConstraints={{ facingMode }}
        screenshotFormat="image/jpeg"
      />
      <div className="flex flex-col gap-4 w-full">
        <button
          className="bg-blue-500 hover:bg-blue-600 cursor-pointer text-white px-4 py-1.5 rounded-md"
          onClick={capture}
        >
          æ’®ã‚‹
        </button>
        <button
          className="bg-gray-500 hover:bg-blue-600 cursor-pointer text-white px-4 py-1.5 rounded-md"
          onClick={switchCamera}
        >
          åˆ‡ã‚Šæ›¿ãˆ
        </button>
        {image && (
          <button
            className="bg-green-500 hover:bg-green-600 cursor-pointer text-white px-4 py-1.5 rounded-md"
            onClick={analyzeImage}
            disabled={isAnalyzing}
          >
            {isAnalyzing ? "åˆ†æä¸­..." : "é¡”ã‚’åˆ†æã™ã‚‹"}
          </button>
        )}
      </div>
      {image && (
        <div className="mt-4">
          <h3 className="mb-2 text-lg font-medium">æ’®å½±ã•ã‚ŒãŸå†™çœŸ</h3>
          <Image
            src={image}
            alt="æ’®å½±ã•ã‚ŒãŸå†™çœŸ"
            width={300}
            height={200}
            style={{
              objectFit: "contain",
              borderRadius: "12px",
            }}
          />
        </div>
      )}
      {faceAnalysisResult && (
        <div className="mt-4 p-4 bg-gray-100 rounded-lg text-black">
          <h3 className="text-lg font-semibold mb-2">åˆ†æçµæœ</h3>
          {faceAnalysisResult.success ? (
            <div>
              <p>æ¤œå‡ºã•ã‚ŒãŸé¡”: {faceAnalysisResult.faceCount}å€‹</p>
              {faceAnalysisResult.faceDetails?.map((face, index) => (
                <div
                  key={index}
                  className="mt-3 p-3 bg-white rounded shadow-sm"
                >
                  <p>
                    å¹´é½¢: ç´„{face.age.low}ï½{face.age.high}æ­³
                  </p>
                  <p>
                    æ€§åˆ¥: {face.gender === "Male" ? "ç”·æ€§" : "å¥³æ€§"} (
                    {Math.round(face.genderConfidence ?? 0)}%)
                  </p>
                  <p>
                    æ„Ÿæƒ…: {translateEmotion(face.emotion)} (
                    {Math.round(face.emotionConfidence ?? 0)}%)
                  </p>
                  <p>ç¬‘é¡”: {face.smile ? "ã‚ã‚Š" : "ãªã—"}</p>
                  <p>çœ¼é¡: {face.eyeglasses ? "ç€ç”¨" : "æœªç€ç”¨"}</p>
                  <p>ã²ã’: {face.beard ? "ã‚ã‚Š" : "ãªã—"}</p>
                  <p>
                    å£ã®é–‹ã: {face.mouthOpen ? "é–‹ã„ã¦ã„ã‚‹" : "é–‰ã˜ã¦ã„ã‚‹"}
                  </p>
                </div>
              ))}
            </div>
          ) : (
            <p>{faceAnalysisResult.message}</p>
          )}
        </div>
      )}
    </div>
  );
}
